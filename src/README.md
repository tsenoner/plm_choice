# Research Repository Structure

This repository has been reorganized to provide a clean, workflow-based structure optimized for manuscript reproduction and research workflows. All code is organized under `src/` by functional purpose.

## Directory Structure

```
src/
â”œâ”€â”€ data_preparation/              # Complete data processing pipeline
â”‚   â”œâ”€â”€ embeddings/               # Embedding generation and processing
â”‚   â”‚   â”œâ”€â”€ embedding_generation.py    # PLM embedding generation
â”‚   â”‚   â”œâ”€â”€ batch_embedding_generation.sh # Batch processing of embeddings
â”‚   â”‚   â””â”€â”€ random_embeddings.py       # Random baseline generation
â”‚   â”œâ”€â”€ 2024_new_proteins/        # Novel protein discovery data pipeline
â”‚   â”‚   â”œâ”€â”€ extract_uniref_to_sqlite.py # UniRef database extraction
â”‚   â”‚   â”œâ”€â”€ get_uniref50.sh            # Download UniRef50 data
â”‚   â”‚   â””â”€â”€ identify_novel_dissimilar_proteins.py # Novel protein identification
â”‚   â”œâ”€â”€ preprocessing.py           # Data cleaning and filtering
â”‚   â”œâ”€â”€ distance_computation.py   # Compute embedding distances
â”‚   â”œâ”€â”€ run_mmseqs_all_vs_all.sh  # Sequence similarity search
â”‚   â”œâ”€â”€ run_foldseek_all_vs_all.sh # Structure similarity search
â”‚   â”œâ”€â”€ merge_mmseqs_foldseek_datasets.py # Combine similarity data
â”‚   â”œâ”€â”€ get_best_pdbs.py          # Extract best ColabFold predictions
â”‚   â””â”€â”€ README.md                 # Data pipeline documentation
â”‚
â”œâ”€â”€ training/                      # Model training and experiments
â”‚   â”œâ”€â”€ run_experiments.py        # ğŸ¯ MAIN ORCHESTRATOR SCRIPT
â”‚   â”œâ”€â”€ train.py                  # Individual model training
â”‚   â”œâ”€â”€ models.py                 # Predictor model definitions
â”‚   â””â”€â”€ predict.py                # Inference module (future)
â”‚
â”œâ”€â”€ evaluation/                    # Model evaluation and metrics
â”‚   â”œâ”€â”€ evaluate.py               # Single model evaluation
â”‚   â”œâ”€â”€ evaluate_multiple.py     # Batch evaluation of multiple runs
â”‚   â””â”€â”€ metrics.py               # Regression metrics calculation
â”‚
â”œâ”€â”€ visualization/                 # All plotting and analysis
â”‚   â”œâ”€â”€ create_performance_summary_plots.py # Performance summary plots
â”‚   â”œâ”€â”€ create_evaluation_grid_plots.py # Evaluation grid layouts
â”‚   â”œâ”€â”€ create_embedding_comparison_plots.py # Embedding comparison wrapper
â”‚   â”œâ”€â”€ pairwise_embedding_comparison.py # Core embedding analysis
â”‚   â”œâ”€â”€ plot_utils.py            # Core plotting utilities
â”‚   â”œâ”€â”€ legacy_*.py              # Deprecated visualization scripts
â”‚   â””â”€â”€ README_pairwise_comparison.md # Pairwise analysis documentation
â”‚
â””â”€â”€ shared/                       # Shared utilities and components
    â”œâ”€â”€ datasets.py              # Data loading utilities
    â”œâ”€â”€ helpers.py               # Common helper functions
    â””â”€â”€ configs/                 # Configuration management
```

## Quick Start

### 1. Main Experimental Workflow

The primary entry point for reproducing results is the experiment orchestrator:

```bash
# Run all model types for all parameters
python src/training/run_experiments.py \
    --csv_dir data/processed/sprot_train \
    --evaluate_after_train \
    --model_types fnn linear linear_distance euclidean

# Run specific combinations
python src/training/run_experiments.py \
    --csv_dir data/processed/sprot_train \
    --model_types fnn linear \
    --target_params fident alntmscore
```

### 2. Data Preparation Pipeline

```bash
# Generate embeddings for all proteins
python src/data_preparation/embeddings/embedding_generation.py sequences.fasta prott5

# Generate random embeddings for baseline comparison
python src/data_preparation/embeddings/random_embeddings.py \
    --template_h5 data/processed/sprot_embs/prott5.h5 \
    --output_dir data/processed/sprot_embs

# Compute distances between protein pairs
python src/data_preparation/distance_computation.py \
    --input_csv data/processed/sprot_train/test.csv \
    --embeddings_dir data/processed/sprot_embs \
    --output_csv data/processed/sprot_train/test_with_distances.csv

# Process sequence/structure similarity
./src/data_preparation/run_mmseqs_all_vs_all.sh sequences.fasta output/mmseqs
./src/data_preparation/run_foldseek_all_vs_all.sh pdb_dir/ output/foldseek
python src/data_preparation/merge_mmseqs_foldseek_datasets.py \
    --mmseqs_file output/mmseqs/results.tsv \
    --foldseek_file output/foldseek/results.tsv \
    --output_file merged_dataset.tsv
```

### 3. Evaluation and Analysis

```bash
# Evaluate a specific trained model
python src/evaluation/evaluate.py --run_dir models/sprot_train/fnn/fident/prott5/20241201_120000

# Batch evaluate multiple runs
python src/evaluation/evaluate_multiple.py --input_path models/sprot_train

# Generate performance summary plots
python src/visualization/create_performance_summary_plots.py \
    --results_dir models/sprot_train \
    --output out/summary_plots

# Create comparison grids
python src/visualization/create_evaluation_grid_plots.py \
    --input_path models/sprot_train \
    --output_dir out/grid_plots

# Generate embedding comparison analysis
python src/visualization/create_embedding_comparison_plots.py \
    --data_path data/processed/sprot_train/test_with_distances.csv \
    --output_dir out/embedding_analysis
```

## Key Features

- **ğŸ“ Workflow-based organization**: Clear separation by research function
- **ğŸš€ Single-command reproduction**: `run_experiments.py` orchestrates everything
- **ğŸ”„ Resumable workflows**: Automatic detection of existing results
- **ğŸ“Š Comprehensive analysis**: Multiple visualization and evaluation tools
- **ğŸ§ª Research-focused**: Optimized for manuscript reproduction, not package distribution
- **ğŸ“ˆ Scalable**: Easy to add new models, metrics, or analyses

## File Naming Conventions

- **Executable scripts**: Use descriptive verbs (e.g., `run_experiments.py`, `create_embedding_comparison_plots.py`)
- **Library modules**: Use nouns (e.g., `models.py`, `metrics.py`, `datasets.py`)
- **Legacy files**: Prefixed with `legacy_` to indicate deprecated functionality
- **Documentation**: `README.md` files in each major directory

## Migration Notes

This structure replaces the previous mixed `scripts/` and `src/unknown_unknowns/` organization with a cleaner, function-based layout. All import statements have been updated to use the new `src.*` namespace.

## Dependencies

All dependencies are managed through `uv` and defined in `pyproject.toml`. The repository is properly configured so that all scripts can be run from the root directory without any path manipulation.

### Running Scripts

**Option 1: Using uv (recommended)**

```bash
# All scripts should be run from the project root using uv
uv run python src/training/run_experiments.py --help
uv run python src/evaluation/evaluate.py --help
uv run python src/visualization/create_embedding_comparison_plots.py --help
uv run python src/visualization/create_performance_summary_plots.py --help
uv run python src/visualization/create_evaluation_grid_plots.py --help
uv run python src/data_preparation/embeddings/embedding_generation.py --help
uv run python src/data_preparation/embeddings/random_embeddings.py --help
```

**Option 2: Activate virtual environment**

```bash
# Activate the environment first, then run scripts
source .venv/bin/activate  # or: uv shell
python src/training/run_experiments.py --help
python src/evaluation/evaluate.py --help
```

### Project Configuration

The repository uses proper Python packaging configuration in `pyproject.toml`:

- Build system: `hatchling`
- Package source: `src/` directory
- All imports use the `src.*` namespace
- No manual path manipulation required

For more details on specific components, see the README files in each subdirectory.
