{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Apple Silicon) device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Using CUDA device:\", torch.cuda.get_device_name(0))\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS (Apple Silicon) device\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World from PyTorch!\n",
      "Tensor on mps: tensor([1., 2., 3.], device='mps:0')\n",
      "Result of operation: tensor([2., 4., 6.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Simple \"Hello World\" example using PyTorch and the detected device\n",
    "print(\"Hello World from PyTorch!\")\n",
    "\n",
    "# Create a small tensor and move it to the detected device\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "x = x.to(device)\n",
    "print(f\"Tensor on {device}: {x}\")\n",
    "\n",
    "# Perform a simple operation to verify device is working\n",
    "y = x * 2\n",
    "print(f\"Result of operation: {y}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- System Information ---\n",
      "PyTorch Version: 2.5.1\n",
      "Python Version: 3.12.9\n",
      "macOS Version: 15.4\n",
      "Using device: mps\n",
      "\n",
      "--- Creating Model and Optimizer ---\n",
      "Model and optimizer created and moved to MPS.\n",
      "\n",
      "--- Starting Training Benchmark ---\n",
      "Batch Size: 256\n",
      "Image Size: 128x128\n",
      "Number of Batches: 100\n",
      "Batch 100/100 completed. Loss: 4.6074\n",
      "\n",
      "--- Benchmark Finished ---\n",
      "Total time for 100 batches: 14.1793 seconds\n",
      "Average Loss: 4.6413\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import platform\n",
    "\n",
    "# --- Basic Setup ---\n",
    "print(f\"--- System Information ---\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Python Version: {platform.python_version()}\")\n",
    "print(f\"macOS Version: {platform.mac_ver()[0]}\")\n",
    "\n",
    "# --- Device Setup (MPS) ---\n",
    "if not torch.backends.mps.is_available():\n",
    "    print(\"MPS backend not available.\")\n",
    "    exit()\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "print(f\"Using device: {device}\\n\")\n",
    "\n",
    "# --- Benchmark Parameters ---\n",
    "batch_size = 256        # Process data in larger chunks for parallelism\n",
    "num_batches = 100       # Number of training iterations\n",
    "image_size = 128        # Size of synthetic images (e.g., 128x128)\n",
    "num_classes = 100       # Number of output classes for the model\n",
    "\n",
    "# --- Define a Simple CNN Model ---\n",
    "# A slightly more complex model to increase computational load\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1), # 3 input channels (RGB)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # Calculate the flattened size after conv/pool layers\n",
    "        # This depends on image_size and the layers above\n",
    "        # For image_size=128: 128 -> 64 -> 32 -> 16. So flattened size = 128 * 16 * 16\n",
    "        # Adjust if you change image_size or network structure\n",
    "        flattened_size = 128 * (image_size // 8) * (image_size // 8)\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flattened_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "print(\"--- Creating Model and Optimizer ---\")\n",
    "model = SimpleCNN(num_classes).to(device)\n",
    "# Use AdamW which can sometimes be slightly more demanding than standard Adam\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss() # Standard loss function\n",
    "print(\"Model and optimizer created and moved to MPS.\\n\")\n",
    "\n",
    "# --- Training Loop Benchmark ---\n",
    "print(f\"--- Starting Training Benchmark ---\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Image Size: {image_size}x{image_size}\")\n",
    "print(f\"Number of Batches: {num_batches}\")\n",
    "\n",
    "model.train() # Set model to training mode\n",
    "total_loss = 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(num_batches):\n",
    "    # 1. Generate synthetic data and labels directly on the MPS device\n",
    "    inputs = torch.randn(batch_size, 3, image_size, image_size, device=device)\n",
    "    labels = torch.randint(0, num_classes, (batch_size,), device=device)\n",
    "\n",
    "    # 2. Forward pass\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # 3. Calculate loss\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # 4. Backward pass (gradient computation - often the most intensive part)\n",
    "    optimizer.zero_grad() # Reset gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step (update model weights)\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    print(f\"Batch {i+1}/{num_batches} completed. Loss: {loss.item():.4f}\", end='\\r')\n",
    "\n",
    "# --- Synchronization and Timing ---\n",
    "# Crucial: Ensure all GPU operations are finished before stopping the timer\n",
    "torch.mps.synchronize()\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"\\n\\n--- Benchmark Finished ---\")\n",
    "print(f\"Total time for {num_batches} batches: {end_time - start_time:.4f} seconds\")\n",
    "print(f\"Average Loss: {total_loss / num_batches:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
